{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721c7336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    adjusted_rand_score,\n",
    "    adjusted_mutual_info_score,\n",
    "    homogeneity_score,\n",
    "    completeness_score,\n",
    "    v_measure_score\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcfddfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_data_frame(df):\n",
    "    df_sorted = df.sort_index(axis=1).sort_values(by=list(df.columns))\n",
    "    return hashlib.sha256(pd.util.hash_pandas_object(df_sorted, index=True).values).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "326e42b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_series(series):\n",
    "    series_str = \",\".join(map(str, series.values))\n",
    "    return hashlib.sha256(series_str.encode()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff5fab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_vocab(vocab):\n",
    "    items = sorted(vocab.items(), key=lambda x: x[1])  \n",
    "    vocab_str = \"\\n\".join(f\"{k}:{v}\" for k, v in items)\n",
    "    return hashlib.sha256(vocab_str.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7176926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_sequences(sequences):\n",
    "    flat = []\n",
    "    for seq in sequences:\n",
    "        flat.extend(seq)\n",
    "        flat.append(-1)  # separator to preserve sequence boundaries\n",
    "    return hashlib.sha256(str(flat).encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2da19f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_tensor(tensor):\n",
    "    return hashlib.sha256(tensor.cpu().numpy().tobytes()).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df21b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_number(x):\n",
    "    return hashlib.sha256(str(x).encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64e12ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Release Year</th>\n",
       "      <th>Title</th>\n",
       "      <th>Origin/Ethnicity</th>\n",
       "      <th>Director</th>\n",
       "      <th>Cast</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Wiki Page</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15344</th>\n",
       "      <td>2007</td>\n",
       "      <td>Stardust</td>\n",
       "      <td>American</td>\n",
       "      <td>Matthew Vaughn</td>\n",
       "      <td>Claire Danes, Michelle Pfeiffer, Robert De Niro</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Stardust_(2007_f...</td>\n",
       "      <td>The magical kingdom of Stormhold is surrounded...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Release Year     Title Origin/Ethnicity        Director  \\\n",
       "15344          2007  Stardust         American  Matthew Vaughn   \n",
       "\n",
       "                                                  Cast    Genre  \\\n",
       "15344  Claire Danes, Michelle Pfeiffer, Robert De Niro  fantasy   \n",
       "\n",
       "                                               Wiki Page  \\\n",
       "15344  https://en.wikipedia.org/wiki/Stardust_(2007_f...   \n",
       "\n",
       "                                                    Plot  \n",
       "15344  The magical kingdom of Stormhold is surrounded...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"movies.csv\")\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39c7ff39",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def filter_genres(df, genres):\n",
    "    \"\"\"\n",
    "    Filters the dataset to include only movies belonging to the specified\n",
    "    genres and ensures that the resulting DataFrame has a sequential index.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): Movie dataset containing a 'Genre' column\n",
    "    genres (list): Genres to retain\n",
    "\n",
    "    Return the result as a `pd.DataFrame`.\n",
    "    \"\"\"\n",
    "    \n",
    "    return df[df[\"Genre\"].isin(genres)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a5af8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filter_genres(df, [\"comedy\", \"drama\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ea2803",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST\n",
    "_df = pd.read_csv(\"movies.csv\")\n",
    "_df = filter_genres(_df, [\"comedy\", \"drama\"])\n",
    "assert hash_data_frame(_df) == \"edad962d401b26a758e9cfb7097272c25c68339782ddb87e9bb04558d5f72c26\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9539c6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MANUALLY GRADED TASK\n",
    "def movie_plot_word_counts(df):\n",
    "    \"\"\"\n",
    "    Creates a plot that shows the number of words in the movie plot descriptions.\n",
    "    \"\"\"\n",
    "    df[\"Plot\"].str.split().apply(len).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fecdd2c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "movie_plot_word_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85faae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def preprocess_plot(df):\n",
    "    \"\"\"\n",
    "    Preprocesses the 'Plot' column by converting all text to lowercase and removing the plots \n",
    "    containing more than 1000 words and ensure that the resulting DataFrame has a sequential index. \n",
    "\n",
    "    Returns a pandas DataFrame.\n",
    "    \"\"\"\n",
    "    \n",
    "    df[\"Plot\"] = df[\"Plot\"].str.lower()\n",
    "    word_counts = df[\"Plot\"].str.split().apply(len)\n",
    "    df = df[word_counts <= 1000].reset_index(drop=True)\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18931e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_plot(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94bb819f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TEST\n",
    "_df = pd.read_csv(\"movies.csv\")\n",
    "_df = preprocess_plot(_df)\n",
    "assert hash_data_frame(_df) == \"d960d3d487ec47f0b5ba182b7bc602b63db9c15a1e16076cdf78f60abc4164ef\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31857ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def partition_dataset(df):\n",
    "    \"\"\"\n",
    "    Split the dataset into features (X) and target (y), where the feature used is `Plot` and the target is `Genre`.\n",
    "    Then, divide X and y into training, validation and test sets using an 80:20 ratio.\n",
    "\n",
    "    If you think encoding is necessary use df[column].astype(\"category\").cat.codes\n",
    "\n",
    "    Use `random_state=42` to ensure reproducibility.\n",
    "    \n",
    "    Return the sets in the following order: train_X, val_X, test_X, train_y, val_y, test_y.\n",
    "    \"\"\"\n",
    "    x = df[\"Plot\"]\n",
    "    y = df[\"Genre\"].astype(\"category\").cat.codes\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    train_x, val_x, train_y, val_y = train_test_split(train_x,train_y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    return train_x, val_x, test_x, train_y, val_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db3cfd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, test_X, train_y, val_y, test_y = partition_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7f97209",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "_df = pd.read_csv(\"movies.csv\")\n",
    "_train_X, _val_X, _test_X, _train_y, _val_y, _test_y = partition_dataset(_df)\n",
    "assert hash_series(_train_X) == \"f3f633cca3a7d238c602554f410241506f3dbb31513295c73bd76b77ff9bd34d\"\n",
    "assert hash_series(_val_X) == \"a66099bd3b1843b84f4597741f49550d258b1b41c2a7aa692a52d32e132ceb85\"\n",
    "assert hash_series(_test_X) == \"6ac1e882e03259be257de0c476af663e73286d3718800b0e11760485da25d332\"\n",
    "assert hash_series(_train_y) == \"bb48348267767da5f6eba35c97ee91b0d636f20d87b7603a370f7284d06ada64\"\n",
    "assert hash_series(_val_y) == \"146395270412839a91e034b3e6a7259f083284314818b6a02fd1a5aeb1524a1b\"\n",
    "assert hash_series(_test_y) == \"8e0a6892cc3b60babc4e713216551a3010708a404f1f8cb2ecd47fd48c8eeaaa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51ecac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def build_vocab(texts, max_vocab_size):\n",
    "    \"\"\"\n",
    "    Builds a vocabulary dictionary from a list of text strings.\n",
    "\n",
    "    The function should count word frequencies across all input texts and\n",
    "    assign an integer index to each word. The vocabulary must include the\n",
    "    special tokens \"<PAD>\" with index 0 and \"<OOV>\" with index 1. The remaining\n",
    "    words should be added in descending order of frequency, up to the maximum\n",
    "    vocabulary size.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list of str): List of preprocessed text strings\n",
    "    max_vocab_size (int): Maximum size of the vocabulary, including special\n",
    "                          tokens\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary mapping words to integer indices\n",
    "    \"\"\"\n",
    "    \n",
    "    counter = Counter()\n",
    "    for sentence in texts:\n",
    "        counter.update(sentence.split())\n",
    "        \n",
    "    vocab = {\n",
    "        \"<PAD>\": 0,\n",
    "        \"<OOV>\": 1,\n",
    "    }\n",
    "    \n",
    "    for idx, (word, _) in enumerate(counter.most_common(max_vocab_size - 2), start=2):\n",
    "        vocab[word] = idx\n",
    "        \n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed4c50e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = build_vocab(train_X.values, 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "500bebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEST\n",
    "assert hash_vocab(vocab) == \"cb5e3c6b40506bc7e0aa34474d58a04733b16b4408739ede5cb41812a0d2279e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35b96613",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def texts_to_sequences(texts, vocab):\n",
    "    \"\"\"\n",
    "    Converts a list of text strings into sequences of integer indices using a\n",
    "    given vocabulary.\n",
    "\n",
    "    Each word in a text should be replaced by its corresponding index from the\n",
    "    vocabulary. Words that are not present in the vocabulary must be mapped to\n",
    "    the \"<OOV>\" token.\n",
    "\n",
    "    Parameters:\n",
    "    texts (list of str): List of preprocessed text strings\n",
    "    vocab (dict): Vocabulary mapping words to integer indices\n",
    "\n",
    "    Returns:\n",
    "    list of list of int: List of integer sequences corresponding to the input texts\n",
    "    \"\"\"\n",
    "    \n",
    "    sequences = []\n",
    "    for sentence in texts:\n",
    "        seq = [\n",
    "            vocab.get(word, vocab[\"<OOV>\"])\n",
    "            for word in sentence.split()\n",
    "        ]\n",
    "        sequences.append(seq)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3bf2b731",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = texts_to_sequences(train_X.values, vocab)\n",
    "val_X   = texts_to_sequences(val_X.values, vocab)\n",
    "test_X  = texts_to_sequences(test_X.values, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19adbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEST\n",
    "assert hash_sequences(train_X) == \"0402e69472cc84e0564e02f3fbf556e58b01a6cc9a5a9c864db28d968ea1d649\"\n",
    "assert hash_sequences(val_X) == \"0b6c7bc470d2b19922835e3cc36f733a31a4389dae3cbb21572cd10327660bf7\"\n",
    "assert hash_sequences(test_X) == \"72706aedbae3b45831ca6b62966f6736dd69f1155d65dd8b1252e4a5655a74ed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "56765e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOMATICALLY GRADED TASK\n",
    "def pad(sequences, pad_value=0):\n",
    "    \"\"\"\n",
    "    Pads a list of integer sequences so that all sequences have the same length.\n",
    "\n",
    "    Shorter sequences should be padded with the specified padding value until\n",
    "    they match the length of the longest sequence. The output should be a\n",
    "    tensor suitable for batch processing in a neural network.\n",
    "\n",
    "    Parameters:\n",
    "    sequences (list of list of int): List of integer sequences\n",
    "    pad_value (int, optional): Value used for padding (default is 0)\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Padded tensor of shape (batch_size, max_sequence_length)\n",
    "    \"\"\"\n",
    "    \n",
    "    return pad_sequence(\n",
    "        [torch.tensor(seq, dtype=torch.long) for seq in sequences],\n",
    "        batch_first=True,\n",
    "        padding_value=pad_value\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5175f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = pad(train_X, pad_value=vocab[\"<PAD>\"])\n",
    "val_X   = pad(val_X,pad_value=vocab[\"<PAD>\"])\n",
    "test_X  = pad(test_X, pad_value=vocab[\"<PAD>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82d3fa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TEST \n",
    "assert hash_tensor(train_X) == \"a512664e689288d133c84a6f8033ee516b025abf6f2305a1fbcb3fd6238e040e\"\n",
    "assert hash_tensor(val_X) == \"933f4a3b2c14892052c211291e96b1c5d1e7691549452a485db89790158af032\"\n",
    "assert hash_tensor(test_X) == \"f44f54df5ada534b075b1dea85f3082bae7f0584001873e21891dc58de637373\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e9f6fb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_LSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    CNNâ€“LSTM model for text classification.\n",
    "\n",
    "    The model should consist of the following components (in order):\n",
    "\n",
    "    1. embbedding: An embedding layer that maps token indices to 128-dimensional vectors.\n",
    "\n",
    "    2. conv1: A 1D convolutional layer with:\n",
    "       - 32 output channels\n",
    "       - kernel size of 4\n",
    "\n",
    "       This should be followed by a max-pooling layer with pool size 2.\n",
    "\n",
    "    3. conv2: A second 1D convolutional layer with:\n",
    "       - 64 output channels\n",
    "       - kernel size of 4\n",
    "       - appropriate padding\n",
    "\n",
    "       This should also be followed by a max-pooling layer with pool size 2.\n",
    "\n",
    "    4. Two LSTM layers:\n",
    "       - lstm1: The first LSTM takes the convolutional features as input and has\n",
    "         128 hidden units.\n",
    "       - lstm2: The second LSTM takes the output of the first LSTM and has\n",
    "         64 hidden units.\n",
    "\n",
    "    5. fc: A fully connected (linear) layer.\n",
    "\n",
    "    Hint:\n",
    "    Think carefully about the activation function needed and the number of\n",
    "    output neurons in the final layer. Do NOT apply an activation function in\n",
    "    the model. The activation will be handled later in the optimizer.\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, num_classes):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(\n",
    "            vocab_size, 128, padding_idx=0\n",
    "        )\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(128, 32, kernel_size=4, padding=2)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=4, padding=2)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        \n",
    "        self.lstm1 = nn.LSTM(64, 128, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(128, 64, batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x.permute(0, 2, 1)\n",
    "        \n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        \n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm1(x)\n",
    "        _, (h, _) = self.lstm2(x)\n",
    "        \n",
    "        return self.fc(h[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f4b4b513",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "def initialize_model():\n",
    "    \"\"\"\n",
    "    Initializes and returns a CNN-LSTM model for text classification.\n",
    "\n",
    "    Parameters:\n",
    "    vocab_size (int): Size of the vocabulary\n",
    "    num_classes (int): Number of output classes\n",
    "\n",
    "    Returns:\n",
    "    torch.nn.Module: Initialized CNN-LSTM model\n",
    "    \"\"\"\n",
    "    num_classes = 1\n",
    "    model = CNN_LSTM(vocab_size=len(vocab), num_classes=num_classes)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1c1699af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = initialize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4851e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TEST\n",
    "assert isinstance(model, nn.Module)\n",
    "assert hasattr(model, \"embedding\")\n",
    "assert model.embedding.embedding_dim == 128\n",
    "assert hasattr(model, \"conv1\")\n",
    "assert hasattr(model, \"conv2\")\n",
    "assert model.conv1.out_channels == 32\n",
    "assert model.conv2.out_channels == 64\n",
    "assert hasattr(model, \"lstm1\")\n",
    "assert hasattr(model, \"lstm2\")\n",
    "assert model.lstm1.hidden_size == 128\n",
    "assert model.lstm2.hidden_size == 64\n",
    "assert hasattr(model, \"fc\")\n",
    "assert hash_number(model.fc.out_features) == \"6b86b273ff34fce19d6b804eff5a3f5747ada4eaa22f1d49c01e52ddb7875b4b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01b89e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = torch.tensor(train_y.values, dtype=torch.long)\n",
    "val_y   = torch.tensor(val_y.values, dtype=torch.long)\n",
    "test_y  = torch.tensor(test_y.values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0d5ab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### AUTOGRADED TASK\n",
    "# Define the optimizer and the loss function\n",
    "    # Hint:\n",
    "    # Since no activation function is defined at the output layer, you should choose\n",
    "    # a loss function suitable for this task that internally applies the appropriate\n",
    "    # activation.\n",
    "        \n",
    "# YOUR CODE HERE\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad325e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
